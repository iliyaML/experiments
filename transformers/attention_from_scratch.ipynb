{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV36gfNES65y"
      },
      "source": [
        "References:\n",
        "- https://machinelearningmastery.com/the-attention-mechanism-from-scratch/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6Oja0Xkx9Rg"
      },
      "source": [
        "## Attention From Scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3RYLRRdRjMn",
        "outputId": "19bbd382-a936-4b72-b4a5-8cbe71499ddd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NumPy version: 1.22.4\n",
            "SciPy version: 1.10.1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "\n",
        "# for reproducibility\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "print('NumPy version:', np.__version__)\n",
        "print('SciPy version:', scipy.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofECtShUzpjk"
      },
      "source": [
        "### Word Representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRIu5b3bRk61",
        "outputId": "4d8c8458-4271-4308-a736-12da98aec250"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((3,), (3,), (3,), (3,))"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# encoder representations of four different words\n",
        "word_1 = np.array([1, 0, 0])\n",
        "word_2 = np.array([0, 1, 0])\n",
        "word_3 = np.array([1, 1, 0])\n",
        "word_4 = np.array([0, 0, 1])\n",
        "\n",
        "word_1.shape, word_2.shape, word_3.shape, word_4.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOxO3b-vXDDG",
        "outputId": "e799a65d-5e27-4191-f9e8-7d557d0db68a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4, 3),\n",
              " array([[1, 0, 0],\n",
              "        [0, 1, 0],\n",
              "        [1, 1, 0],\n",
              "        [0, 0, 1]]))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# stacking the word embeddings into a single array\n",
        "words = np.array([word_1, word_2, word_3, word_4])\n",
        "\n",
        "# seq_length (num of words = 4) x embedding dimension (3)\n",
        "words.shape, words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNZ80JeK0tfz"
      },
      "source": [
        "### Generating Query, Key and Value Matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_obKhOiVRqwe",
        "outputId": "baa533e8-10fa-48c7-8e53-9b76f7d67eba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "W_Q (3, 3) [[2 0 2]\n",
            " [2 0 0]\n",
            " [2 1 2]]\n",
            "W_K (3, 3) [[2 2 2]\n",
            " [0 2 1]\n",
            " [0 1 1]]\n",
            "W_V (3, 3) [[1 1 0]\n",
            " [0 1 1]\n",
            " [0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "# generating the weight matrices (simulation)\n",
        "W_Q = np.random.randint(3, size=(3, 3))\n",
        "W_K = np.random.randint(3, size=(3, 3))\n",
        "W_V = np.random.randint(3, size=(3, 3))\n",
        "\n",
        "print('W_Q', W_Q.shape, W_Q)\n",
        "print('W_K', W_K.shape, W_K)\n",
        "print('W_V', W_V.shape, W_V)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi8XtyL_RxXh",
        "outputId": "e61c3f5a-f654-4050-9995-eaf0778257c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3,) (3,) (3,)\n",
            "Q (4, 3) [[2 0 2]\n",
            " [2 0 0]\n",
            " [4 0 2]\n",
            " [2 1 2]]\n",
            "K (4, 3) [[2 2 2]\n",
            " [0 2 1]\n",
            " [2 4 3]\n",
            " [0 1 1]]\n",
            "V (4, 3) [[1 1 0]\n",
            " [0 1 1]\n",
            " [1 2 1]\n",
            " [0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "# generating the queries, keys and values\n",
        "query_1 = word_1 @ W_Q # 1x3 @ 3x3 = 1x3\n",
        "key_1 = word_1 @ W_K\n",
        "value_1 = word_1 @ W_V\n",
        " \n",
        "query_2 = word_2 @ W_Q\n",
        "key_2 = word_2 @ W_K\n",
        "value_2 = word_2 @ W_V\n",
        " \n",
        "query_3 = word_3 @ W_Q\n",
        "key_3 = word_3 @ W_K\n",
        "value_3 = word_3 @ W_V\n",
        " \n",
        "query_4 = word_4 @ W_Q\n",
        "key_4 = word_4 @ W_K\n",
        "value_4 = word_4 @ W_V\n",
        "\n",
        "print(query_1.shape, key_1.shape, value_1.shape)\n",
        "\n",
        "Q = np.array([query_1, query_2, query_3, query_4])\n",
        "K = np.array([key_1, key_2, key_3, key_4])\n",
        "V = np.array([value_1, value_2, value_3, value_4])\n",
        "\n",
        "print('Q', Q.shape, Q)\n",
        "print('K', K.shape, K)\n",
        "print('V', V.shape, V)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFsrzEioVWyl",
        "outputId": "c6847a51-7897-4b3f-aed1-3e6a68530338"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q (4, 3) [[2 0 2]\n",
            " [2 0 0]\n",
            " [4 0 2]\n",
            " [2 1 2]]\n",
            "K (4, 3) [[2 2 2]\n",
            " [0 2 1]\n",
            " [2 4 3]\n",
            " [0 1 1]]\n",
            "V (4, 3) [[1 1 0]\n",
            " [0 1 1]\n",
            " [1 2 1]\n",
            " [0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "# Matrix version of above\n",
        "# generating the queries, keys and values\n",
        "Q = words @ W_Q # 4x3 @ 3x3 = 4x3\n",
        "K = words @ W_K\n",
        "V = words @ W_V\n",
        "\n",
        "print('Q', Q.shape, Q)\n",
        "print('K', K.shape, K)\n",
        "print('V', V.shape, V)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QENZPNQEyp71"
      },
      "source": [
        "### Example: Working only on the first word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7noIUW9MR2A7",
        "outputId": "98dde44e-2b4d-4760-808a-3867d91062aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4,), array([ 8,  2, 10,  2]))"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# scoring the first query vector against all key vectors\n",
        "scores = np.array([\n",
        "    np.dot(query_1, key_1), \n",
        "    np.dot(query_1, key_2), \n",
        "    np.dot(query_1, key_3), \n",
        "    np.dot(query_1, key_4)\n",
        "])\n",
        "scores.shape, scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCbeFDgXR3ha",
        "outputId": "fcc654f6-a251-4260-ce76-2f2d4e83ea9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4,), array([0.23608986, 0.00738988, 0.74913039, 0.00738988]))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# computing the weights by a softmax operation\n",
        "weights = scipy.special.softmax(scores / key_1.shape[0] ** 0.5)\n",
        "weights.shape, weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5WGP9UISH_s",
        "outputId": "a22e7d6b-e3bb-441c-a010-9d0973bc571c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((3,), array([0.98522025, 1.74174051, 0.75652026]))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# computing the attention by a weighted sum of the value vectors\n",
        "attention = (weights[0] * value_1) + (weights[1] * value_2) + \\\n",
        "          (weights[2] * value_3) + (weights[3] * value_4)\n",
        "attention.shape, attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4xGyK25R9tM",
        "outputId": "c8ee8a14-51ff-4a8e-8406-069eea747494"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((3,), array([0.98522025, 1.74174051, 0.75652026]))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# equivalent to above   1x4 @ 4x3 = 1x3\n",
        "attention = weights @ np.array([value_1, value_2, value_3, value_4])\n",
        "attention.shape, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6O4THz90J_k"
      },
      "source": [
        "### Matrix Form"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk9xN8P7b-kF",
        "outputId": "f7975e64-0ab2-4527-ff76-7bae65ebb331"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4, 3),\n",
              " array([[2, 0, 2],\n",
              "        [2, 0, 0],\n",
              "        [4, 0, 2],\n",
              "        [2, 1, 2]]))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Q.shape, Q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaX9pYyMcAol",
        "outputId": "87ff3e2a-6035-4b80-80d1-59fe31962941"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4, 3),\n",
              " array([[2, 2, 2],\n",
              "        [0, 2, 1],\n",
              "        [2, 4, 3],\n",
              "        [0, 1, 1]]))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "K.shape, K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZv82yzzcQZn",
        "outputId": "becb71ac-5e02-46b6-b450-d1f9dcc3b833"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((3, 4),\n",
              " array([[2, 0, 2, 0],\n",
              "        [2, 2, 4, 1],\n",
              "        [2, 1, 3, 1]]))"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "K.transpose().shape, K.transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtPo9gx3X6Cm",
        "outputId": "8d39ddd6-217e-401d-ce91-072d67c05720"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4, 4),\n",
              " array([[ 8,  2, 10,  2],\n",
              "        [ 4,  0,  4,  0],\n",
              "        [12,  2, 14,  2],\n",
              "        [10,  4, 14,  3]]))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# scoring the query vectors against all key vectors\n",
        "scores = Q @ K.transpose()\n",
        "scores.shape, scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAVOI-0MYmJQ",
        "outputId": "4c877c8f-2648-42d5-d141-0724c7d744fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4, 4),\n",
              " array([[2.36089863e-01, 7.38987555e-03, 7.49130386e-01, 7.38987555e-03],\n",
              "        [4.54826323e-01, 4.51736775e-02, 4.54826323e-01, 4.51736775e-02],\n",
              "        [2.39275049e-01, 7.43870015e-04, 7.59237211e-01, 7.43870015e-04],\n",
              "        [8.99501754e-02, 2.81554063e-03, 9.05653685e-01, 1.58059922e-03]]))"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# computing the weights by a softmax operation\n",
        "weights = scipy.special.softmax(scores / K.shape[1] ** 0.5, axis=1)\n",
        "weights.shape, weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUSBcvbT6AaT",
        "outputId": "c106f148-6d1b-4931-dfa8-8f7d3a5e86e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4, 3),\n",
              " array([[1, 1, 0],\n",
              "        [0, 1, 1],\n",
              "        [1, 2, 1],\n",
              "        [0, 0, 0]]))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "V.shape, V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrLWKLBlYpuK",
        "outputId": "c7d7634b-ec02-4e95-d60c-2dfab78018a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4, 3),\n",
              " array([[0.98522025, 1.74174051, 0.75652026],\n",
              "        [0.90965265, 1.40965265, 0.5       ],\n",
              "        [0.99851226, 1.75849334, 0.75998108],\n",
              "        [0.99560386, 1.90407309, 0.90846923]]))"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# computing the attention by a weighted sum of the value vectors\n",
        "attention = weights @ V\n",
        "attention.shape, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO8-eRn7S5F_"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sw5gfQfhTqJu",
        "outputId": "045187ae-d7bb-400f-fd5c-124be02c57fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.98522025 1.74174051 0.75652026]\n",
            " [0.90965265 1.40965265 0.5       ]\n",
            " [0.99851226 1.75849334 0.75998108]\n",
            " [0.99560386 1.90407309 0.90846923]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        " \n",
        "# for reproducibility\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# encoder representations of four different words\n",
        "word_1 = np.array([1, 0, 0])\n",
        "word_2 = np.array([0, 1, 0])\n",
        "word_3 = np.array([1, 1, 0])\n",
        "word_4 = np.array([0, 0, 1])\n",
        " \n",
        "# stacking the word embeddings into a single array\n",
        "words = np.array([word_1, word_2, word_3, word_4])\n",
        " \n",
        "# generating the weight matrices\n",
        "W_Q = np.random.randint(3, size=(3, 3))\n",
        "W_K = np.random.randint(3, size=(3, 3))\n",
        "W_V = np.random.randint(3, size=(3, 3))\n",
        " \n",
        "# generating the queries, keys and values\n",
        "Q = words @ W_Q\n",
        "K = words @ W_K\n",
        "V = words @ W_V\n",
        " \n",
        "# scoring the query vectors against all key vectors\n",
        "scores = Q @ K.transpose()\n",
        " \n",
        "# computing the weights by a softmax operation\n",
        "weights = scipy.special.softmax(scores / K.shape[1] ** 0.5, axis=1)\n",
        " \n",
        "# computing the attention by a weighted sum of the value vectors\n",
        "attention = weights @ V\n",
        " \n",
        "print(attention)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z04AA2y2t34-"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qL_Bt6bStzmA",
        "outputId": "45fe4c3f-0219-4990-845d-38d6fa1952a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting session-info\n",
            "  Downloading session_info-1.0.0.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting stdlib_list\n",
            "  Downloading stdlib_list-0.8.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: session-info\n",
            "  Building wheel for session-info (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for session-info: filename=session_info-1.0.0-py3-none-any.whl size=8042 sha256=0811235994491fc716052bf87e24407e9a68d12864596e742bb3bbff6527ae07\n",
            "  Stored in directory: /root/.cache/pip/wheels/d4/fc/2e/00ca60bac7954b84907efd41baa9b4853500eaeec4228410c6\n",
            "Successfully built session-info\n",
            "Installing collected packages: stdlib_list, session-info\n",
            "Successfully installed session-info-1.0.0 stdlib_list-0.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install session-info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "60w3a2ukt66r",
        "outputId": "87ab8c97-3956-4410-93ca-f872fbab53f5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<details>\n",
              "<summary>Click to view session information</summary>\n",
              "<pre>\n",
              "-----\n",
              "numpy               1.22.4\n",
              "scipy               1.10.1\n",
              "session_info        1.0.0\n",
              "-----\n",
              "</pre>\n",
              "<details>\n",
              "<summary>Click to view modules imported as dependencies</summary>\n",
              "<pre>\n",
              "PIL                 8.4.0\n",
              "backcall            0.2.0\n",
              "certifi             2022.12.07\n",
              "cffi                1.15.1\n",
              "cycler              0.10.0\n",
              "cython_runtime      NA\n",
              "dateutil            2.8.2\n",
              "debugpy             1.6.6\n",
              "decorator           4.4.2\n",
              "defusedxml          0.7.1\n",
              "google              NA\n",
              "httplib2            0.21.0\n",
              "importlib_resources NA\n",
              "ipykernel           5.5.6\n",
              "ipython_genutils    0.2.0\n",
              "kiwisolver          1.4.4\n",
              "matplotlib          3.7.1\n",
              "matplotlib_inline   0.1.6\n",
              "mpl_toolkits        NA\n",
              "packaging           23.0\n",
              "pexpect             4.8.0\n",
              "pickleshare         0.7.5\n",
              "pkg_resources       NA\n",
              "platformdirs        3.2.0\n",
              "portpicker          NA\n",
              "prompt_toolkit      3.0.38\n",
              "psutil              5.9.4\n",
              "ptyprocess          0.7.0\n",
              "pydev_ipython       NA\n",
              "pydevconsole        NA\n",
              "pydevd              2.9.5\n",
              "pydevd_file_utils   NA\n",
              "pydevd_plugins      NA\n",
              "pydevd_tracing      NA\n",
              "pygments            2.14.0\n",
              "pyparsing           3.0.9\n",
              "sitecustomize       NA\n",
              "six                 1.16.0\n",
              "socks               1.7.1\n",
              "sphinxcontrib       NA\n",
              "storemagic          NA\n",
              "tornado             6.2\n",
              "traitlets           5.7.1\n",
              "wcwidth             0.2.6\n",
              "zipp                NA\n",
              "zmq                 23.2.1\n",
              "</pre>\n",
              "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
              "<pre>\n",
              "-----\n",
              "IPython             7.34.0\n",
              "jupyter_client      6.1.12\n",
              "jupyter_core        5.3.0\n",
              "notebook            6.3.0\n",
              "-----\n",
              "Python 3.9.16 (main, Dec  7 2022, 01:11:51) [GCC 9.4.0]\n",
              "Linux-5.10.147+-x86_64-with-glibc2.31\n",
              "-----\n",
              "Session information updated at 2023-04-01 23:37\n",
              "</pre>\n",
              "</details>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import session_info\n",
        "\n",
        "session_info.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "01fd550304b9e7cfb3e25c8e3ca63c0030fb0173de6652dd3d36373edc7c122f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

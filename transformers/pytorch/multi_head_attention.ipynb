{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "References:\n",
        "- https://www.youtube.com/watch?v=HQn1QKQYXVg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LAazCLV5nmLf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Nrw4LSZroRwa"
      },
      "outputs": [],
      "source": [
        "sequence_length = 4 # length of input sentence, typically set a maximum sequence \n",
        "                    # so that all your vectors are goign to be fixed size\n",
        "batch_size = 1      # going to help with parallel processing\n",
        "input_dim = 512 # vector dimension of every word that goes into the\n",
        "                      # Attention Unit\n",
        "d_model = 512 # output of the Attention Unit for every single word\n",
        "x = torch.randn( (batch_size, sequence_length, input_dim) ) \n",
        "# some randomely sampled input since we're not going to be creating the \n",
        "# position encoding in the input phase right now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wccayjIyp86D",
        "outputId": "24d7f5e4-13a4-4f74-88af-f6b3f0add601"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 512])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.size()\n",
        "# input is going to be batch_size x sequence_length x input_dim\n",
        "\n",
        "# Note: x is what goes directly into the Encoder part of the transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OJCtqEWJqPO2"
      },
      "outputs": [],
      "source": [
        "qkv_layer = nn.Linear(input_dim, 3 * d_model)\n",
        "# now we're going to be mapping the input from this dimension (input_dim) of \n",
        "# 512 to  3 times the model dimension (3 * 512)\n",
        "\n",
        "# this is done to create the Q, K, V vectors all concatenated\n",
        "# all of them have the 8 attention heads which we will split up later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "08tpKZJUqjWh"
      },
      "outputs": [],
      "source": [
        "qkv = qkv_layer(x)\n",
        "# we pass the input x to this layer to generate the qkv vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mS2e7VrrKdG",
        "outputId": "a5b9e768-59e5-4685-f692-724c2de304dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 1536])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qkv.shape\n",
        "# it's one batch, 4 words, and each word vector is 1536 in size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "oCuFRDUYrR4-",
        "outputId": "96cdffb9-fb9e-4858-e0f0-5cabc39e044d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'qkv distribution')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "y_val = torch.histc(qkv, bins=200, min=-3, max=3)\n",
        "x_val = np.arange(-1, 1, 0.01) * 3\n",
        "plt.bar(x_val, y_val, align='center', color=['forestgreen'])\n",
        "plt.title('qkv distribution')\n",
        "\n",
        "# to get an idea of like what are the kind of values that we\n",
        "# see here and since I'm sampling from a random normal distribution you'll see\n",
        "# the values that look like this but this distribution of all the values in \n",
        "# this entire tensor is going to be very different depending on how we generate\n",
        "# the data depending on the positional encodings and the inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nqutfyOtroYO"
      },
      "outputs": [],
      "source": [
        "num_heads = 8 # number of attention heads\n",
        "head_dim = d_model // num_heads # 512 / 8 = 64\n",
        "\n",
        "# we will now reshape our qkv\n",
        "# Matrix to break down the last Dimension\n",
        "# into a product of the number of heads\n",
        "qkv = qkv.reshape(batch_size, sequence_length, num_heads, 3 * head_dim)\n",
        "# the 3 exists because of the combination of Q, K, V vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpfkgKMtsGb3",
        "outputId": "36c018f4-13dd-468e-d083-2a81e074b68c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 8, 192])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qkv.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MmjZ7iwsVH_",
        "outputId": "43a1c631-c80f-4657-c450-8ffdfcb8cca1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 192])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# I'm going to be switching around just the second and the third\n",
        "# Dimensions so that the head is over here and then the number of sequences \n",
        "# is over here so it's easier to perform parallel operations on these \n",
        "# last two Dimensions\n",
        "qkv = qkv.permute(0, 2, 1, 3) \n",
        "# [batch_size, num_heads, sequence_length, 3*head_dim]\n",
        "qkv.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbO1h3_HsfWS",
        "outputId": "29b66274-17e0-451d-8eec-b4bef18be5f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([1, 8, 4, 64]),\n",
              " torch.Size([1, 8, 4, 64]),\n",
              " torch.Size([1, 8, 4, 64]))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# now we obtain the query key and value vectors individually by basically\n",
        "# breaking down this entire tensor by its last Dimension and \n",
        "# hence the input is -1\n",
        "q, k, v = qkv.chunk(3, dim=-1)\n",
        "# this is where you see the query key and value Vector is broken down as I\n",
        "# mentioned before\n",
        "q.shape, k.shape, v.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj6zXmqxA5_t"
      },
      "source": [
        "Self Attention for Multiple Heads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nw0mzc_sths",
        "outputId": "78ef155f-c23b-4ae0-8b40-54a1f3ba68ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 4])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d_k = q.size()[-1] # get the size of one of these vectors, should be 64\n",
        "\n",
        "# every word has a query vector and it's goign to compare its query vector\n",
        "# to every other words key vector\n",
        "# and that's represented by this matrix multiplication over here\n",
        "scaled = torch.matmul(q, k.transpose(-2, -1)) / np.sqrt(d_k)\n",
        "# Note: you have to use the transpose function and you can't just do like a\n",
        "# DOT T to typically transpose because these are tensors that are four\n",
        "# dimensional and not simply just two-dimensional matrices and so we\n",
        "# specify the transpose along with the dimensions along which we want to\n",
        "# transpose in this case we wanted to transpose the last two Dimensions which\n",
        "# are the (sequence length) as well as the \n",
        "# (dimension size or the head Dimension size) for every one of these words \n",
        "# in every head and so the last two dimensions of\n",
        "# the query Vector are like 4x64. this (k.transpose) will be a 64 cross 4 \n",
        "# and so we'll end with a up with a 4x4 Matrix which is basically the\n",
        "# sequence length by the sequence length\n",
        "scaled.shape\n",
        "# scaling here to make sure the variance of these values is much smaller\n",
        "# so that these values just don't go out of control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIMdCcQdA9Tk",
        "outputId": "b5b5f066-226e-4780-e972-f03186290efd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-879c2705464e>:1: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3277.)\n",
            "  k.T.shape\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([64, 4, 8, 1])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k.T.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a0ZDbmaE-EH",
        "outputId": "5e56be07-bec8-4cdf-e115-15f045f791e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.4977,  0.1775],\n",
              "        [-0.5478, -2.2037],\n",
              "        [ 0.0158, -1.5107]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# example of transpose\n",
        "y = torch.randn(2, 3)\n",
        "torch.transpose(y, 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7A6gMtYFpQX",
        "outputId": "1e1df51e-3bc0-493c-e290-26a269ac0b3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.4977,  0.1775],\n",
              "        [-0.5478, -2.2037],\n",
              "        [ 0.0158, -1.5107]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.transpose(y, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXLgbeKrG5OQ",
        "outputId": "e8f7d402-90ee-4bac-8ef9-27bc7d40a722"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          ...,\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True]],\n",
              "\n",
              "         [[True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          ...,\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True]],\n",
              "\n",
              "         [[True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          ...,\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          ...,\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True]],\n",
              "\n",
              "         [[True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          ...,\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True]],\n",
              "\n",
              "         [[True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          ...,\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True]]]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k.transpose(-1, -2) == k.transpose(-2, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmbitLQfG8nH",
        "outputId": "c986eef0-6a5f-4861-8b2d-5402ebf02958"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 64, 4])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k.transpose(-1, -2).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4GXkZbdFsPa",
        "outputId": "e70478d8-c8f5-4b30-f514-7c0ddf3d0b3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., -inf, -inf, -inf],\n",
              "        [0., 0., -inf, -inf],\n",
              "        [0., 0., 0., -inf],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Masking\n",
        "# required for self-attention\n",
        "# this is done to ensure the decoder does not cheat \n",
        "# the goal of the attention mechanism is to gain context from the words\n",
        "# that are around it during the encoding phase, we actually \n",
        "# have all words which are passed in in parallel simultaneously \n",
        "# so we can generate vectors by taking the context\n",
        "# of words that come before it as well as words that come after in the decoder\n",
        "\n",
        "# in the decoder however, we generate words one at a time so when generating\n",
        "# context, we only want to look at words that come before it because we don't\n",
        "# event have the words that come after it\n",
        "mask = torch.full(scaled.size() , float('-inf'))\n",
        "mask = torch.triu(mask, diagonal=1)\n",
        "mask[0][1] # mask for a single head it'll look like this \n",
        "\n",
        "# note: it's the same exact dimension as our scaled vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyFifsWiHASz",
        "outputId": "6fe90073-370b-49cb-c8a9-16a42b9aed9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.5910,    -inf,    -inf,    -inf],\n",
              "        [-0.2502, -0.5378,    -inf,    -inf],\n",
              "        [-0.2204, -0.0691, -0.6483,    -inf],\n",
              "        [ 0.1347,  1.1368,  0.2762,  0.1638]], grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(scaled + mask)[0][0] # add them both together\n",
        "\n",
        "# this is the tensor for one head which will be a 4x4 matrix\n",
        "# upper diagonal elements would be the negative infinity now\n",
        "# we're doing negative infinity because we're going to do softmax which takes\n",
        "# like exponents, the exponents of zero will become one\n",
        "# the exponents of -infinity will become zero so that you cannot cheat and\n",
        "# look forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Ni502FKFekal"
      },
      "outputs": [],
      "source": [
        "scaled += mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Q8oNFmE1enOn"
      },
      "outputs": [],
      "source": [
        "# apply built in softmax function\n",
        "# and we apply it to the last dimension, which incorporates the row itself\n",
        "attention = F.softmax(scaled, dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s8JHiXCepRm",
        "outputId": "6bb6f10b-1c78-4a62-8ba8-31b3f51ec469"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 4])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attention.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAZauTOjeqgZ",
        "outputId": "80c8c476-82b9-4b5f-d175-8831dcf50850"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5714, 0.4286, 0.0000, 0.0000],\n",
              "        [0.3552, 0.4132, 0.2315, 0.0000],\n",
              "        [0.1693, 0.4612, 0.1951, 0.1743]], grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attention[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmUa0cHiesOI",
        "outputId": "519cbd1d-0173-4978-8a7c-f0f8fa2b4446"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 64])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# we now take this value vector (v), remember this is what is actually being\n",
        "# offered by every single word in order to generate new value vectors\n",
        "values = torch.matmul(attention, v)\n",
        "\n",
        "# the idea here is that these new value vectors are going to be much more \n",
        "# context aware than the original value vectors in the original input\n",
        "\n",
        "# so we'll end up for every batch, for every head, for every word, in the \n",
        "# sequence we'll have a 64 dimensional vector\n",
        "values.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjCpbLHYext7"
      },
      "source": [
        "Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "XqMUepOTet2r"
      },
      "outputs": [],
      "source": [
        "def scaled_dot_product(q, k, v, mask=None):\n",
        "    d_k = q.size()[-1]\n",
        "    scaled = torch.matmul(q, k.transpose(-1, -2)) / np.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        scaled += mask\n",
        "    attention = F.softmax(scaled, dim=-1)\n",
        "    values = torch.matmul(attention, v)\n",
        "    return values, attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "I0SKAD8Ie0oK"
      },
      "outputs": [],
      "source": [
        "values, attention = scaled_dot_product(q, k, v, mask=mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU3GK2bHe3NE",
        "outputId": "d57f8318-b204-433f-cb49-c87f8df9d1c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 4])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attention.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6RFWURNfak1",
        "outputId": "b3a25713-b727-4dd3-926a-12122935f4d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5714, 0.4286, 0.0000, 0.0000],\n",
              "        [0.3552, 0.4132, 0.2315, 0.0000],\n",
              "        [0.1693, 0.4612, 0.1951, 0.1743]], grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attention[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fzVoVJqfbyR",
        "outputId": "1ae3a405-673d-4d81-f269-9c9d98af27a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 64])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# we can now have all of the value vectors for every single attention head,\n",
        "# for every single word which are 64 dimensional vectors\n",
        "values.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDhC9Zp4fdkO",
        "outputId": "7ca996ef-d9b6-4c18-d9ec-6679768f73d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 512])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# combine or concatenate all of those heads together and for eight heads\n",
        "# we're going to now make them 512 dimensional vectors which is exactly the\n",
        "# input dimension\n",
        "values = values.reshape(batch_size, sequence_length, num_heads * head_dim)\n",
        "values.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "5e2q-80effN_"
      },
      "outputs": [],
      "source": [
        "# then so that these heads can also communicate with each other the\n",
        "# information that they've learned we are just going to pass it through a linear\n",
        "# layer which is just a feed forward layer of 512x512 and this \n",
        "# doesn't change the dimension\n",
        "linear_layer = nn.Linear(d_model, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "f4E39wsffgkl"
      },
      "outputs": [],
      "source": [
        "out = linear_layer(values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQ5rFw3SfiJl",
        "outputId": "4f1486c9-fe01-4677-fc0c-e87ed9d33e88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 512])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# this output vector is going the be much more context aware than \n",
        "# the input vector was\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHutF8CNfkXr",
        "outputId": "19b168e2-3b7e-462a-af18-585aed88aa89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[-0.0865,  0.2972, -0.1460,  ...,  0.3308, -0.6109, -0.5209],\n",
              "         [-0.0402,  0.1618, -0.0970,  ...,  0.3004,  0.0423,  0.1351],\n",
              "         [ 0.0311,  0.0759, -0.1420,  ...,  0.0654,  0.0637, -0.2134],\n",
              "         [-0.0801, -0.0453,  0.2696,  ...,  0.0900, -0.1515,  0.3044]]],\n",
              "       grad_fn=<ViewBackward0>)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lkMKxO5fmxV"
      },
      "source": [
        "Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "210afyLKflgg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def scaled_dot_product(q, k, v, mask=None):\n",
        "    d_k = q.size()[-1]\n",
        "    scaled = torch.matmul(q, k.transpose(-1, -2)) / np.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        scaled += mask\n",
        "    attention = F.softmax(scaled, dim=-1)\n",
        "    values = torch.matmul(attention, v)\n",
        "    return values, attention\n",
        "\n",
        "class MultiheadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "        self.qkv_layer = nn.Linear(input_dim , 3 * d_model)\n",
        "        self.linear_layer = nn.Linear(d_model, d_model)\n",
        "    \n",
        "    def forward(self, x, mask=None):\n",
        "        batch_size, sequence_length, input_dim = x.size()\n",
        "        print(f\"x.size(): {x.size()}\")\n",
        "        qkv = self.qkv_layer(x)\n",
        "        print(f\"qkv.size(): {qkv.size()}\")\n",
        "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim)\n",
        "        print(f\"qkv.size(): {qkv.size()}\")\n",
        "        qkv = qkv.permute(0, 2, 1, 3)\n",
        "        print(f\"qkv.size(): {qkv.size()}\")\n",
        "        q, k, v = qkv.chunk(3, dim=-1)\n",
        "        print(f\"q size: {q.size()}, k size: {k.size()}, v size: {v.size()}, \")\n",
        "        values, attention = scaled_dot_product(q, k, v, mask)\n",
        "        print(f\"values.size(): {values.size()}, attention.size:{ attention.size()} \")\n",
        "        values = values.reshape(batch_size, sequence_length, self.num_heads * self.head_dim)\n",
        "        print(f\"values.size(): {values.size()}\")\n",
        "        out = self.linear_layer(values)\n",
        "        print(f\"out.size(): {out.size()}\")\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeK6RzfrfswU"
      },
      "source": [
        "Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEIr_pRlfq5C",
        "outputId": "be347d5b-994c-4895-d303-f664eee4ca8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x.size(): torch.Size([30, 5, 1024])\n",
            "qkv.size(): torch.Size([30, 5, 1536])\n",
            "qkv.size(): torch.Size([30, 5, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 5, 192])\n",
            "q size: torch.Size([30, 8, 5, 64]), k size: torch.Size([30, 8, 5, 64]), v size: torch.Size([30, 8, 5, 64]), \n",
            "values.size(): torch.Size([30, 8, 5, 64]), attention.size:torch.Size([30, 8, 5, 5]) \n",
            "values.size(): torch.Size([30, 5, 512])\n",
            "out.size(): torch.Size([30, 5, 512])\n"
          ]
        }
      ],
      "source": [
        "input_dim = 1024\n",
        "d_model = 512\n",
        "num_heads = 8\n",
        "\n",
        "batch_size = 30\n",
        "sequence_length = 5\n",
        "x = torch.randn( (batch_size, sequence_length, input_dim) )\n",
        "\n",
        "model = MultiheadAttention(input_dim, d_model, num_heads)\n",
        "out = model.forward(x)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "01fd550304b9e7cfb3e25c8e3ca63c0030fb0173de6652dd3d36373edc7c122f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

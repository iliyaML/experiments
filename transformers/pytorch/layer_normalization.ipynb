{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCJAsBKVumoK"
      },
      "source": [
        "References:\n",
        "- https://www.youtube.com/watch?v=G45TuC6zRf4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yauMbbQbJ5Jk"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nxuhTtRwLOo",
        "outputId": "23f12074-e804-4768-8038-3c2cd64ba9aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 2 3\n",
            "tensor([[[0.2000, 0.1000, 0.3000],\n",
            "         [0.5000, 0.1000, 0.1000]]])\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "I've added a Batch Dimension to the same exact input that we have \n",
        "this is because during training we typically would have a batch\n",
        "Dimension so that it helps parallelize training and training just becomes\n",
        "faster \n",
        "\n",
        "so we would reshape the input to be: \n",
        "the number of words which is two\n",
        "in this case I've taken the batch size as one \n",
        "and we're going to see the embedding for each batch as just three\n",
        "\"\"\"\n",
        "\n",
        "inputs = torch.Tensor([[[0.2, 0.1, 0.3], [0.5, 0.1, 0.1]]])\n",
        "\n",
        "# batch, number of words, embedding\n",
        "B, S, E = inputs.size()\n",
        "\n",
        "print(B, S, E)\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL65EVE_J7KO",
        "outputId": "9ff896d6-9920-4e52-db96-76041d664fb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 1, 3])\n",
            "tensor([[[0.2000, 0.1000, 0.3000]],\n",
            "\n",
            "        [[0.5000, 0.1000, 0.1000]]])\n"
          ]
        }
      ],
      "source": [
        "inputs = inputs.reshape(S, B, E)\n",
        "\n",
        "print(inputs.size())\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--zvWWq2KLl1",
        "outputId": "e6374a1f-4267-4254-d2ee-5a6ca2222b2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([1, 3]), torch.Size([1, 3]))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "because now we have like this batch Dimension \n",
        "we're also going to use layer normalization not only just for the last\n",
        "layer but that last layer across some batches \n",
        "\n",
        "in this case it's going to be one (batch dimension) so it's not going \n",
        "to make too much of a difference \n",
        "\n",
        "but layer normalization is essentially going to be computed\n",
        "across the layer and also the batch just for your reference\n",
        "\"\"\"\n",
        "\n",
        "parameter_shape = inputs.size()[-2:]\n",
        "\n",
        "\"\"\"\n",
        "that's kind of why we see one by three dimensional matrices otherwise we would\n",
        "have just seen just three dimensional vectors for gamma and beta and \n",
        "\n",
        "we're going to initialize gamma to be the standard deviation which is just ones\n",
        "whereas betas are just going to be a bunch of zeros\n",
        "\"\"\"\n",
        "gamma = torch.nn.Parameter(torch.ones(parameter_shape))\n",
        "beta =  torch.nn.Parameter(torch.zeros(parameter_shape))\n",
        "\n",
        "\"\"\"\n",
        "in this case that's kind of why we see 1 x 3 dimensional matrices \n",
        "otherwise we would have just seen just three dimensional vectors \n",
        "for gamma and beta\n",
        "\"\"\"\n",
        "gamma.size(), beta.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85ajY22cJ5Bg",
        "outputId": "60ae5aa9-e2c1-4749-ef3e-662166ee5c5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([1, 3]), [-1, -2])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "now I'm basically computing the dimensions for which we want \n",
        "to compute layer normalization that is:\n",
        "the batch Dimension as well as the embedding Dimension \n",
        "\n",
        "and  it's the last two layers\n",
        "\"\"\"\n",
        "dims = [-(i + 1) for i in range(len(parameter_shape))]\n",
        "\n",
        "parameter_shape, dims"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py8DHV7AMX6y",
        "outputId": "203526f7-3301-4cd5-b259-6fe227c7802f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([2, 1, 1]), tensor([[[0.2000]],\n",
              " \n",
              "         [[0.2333]]]))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "now we'll just take the mean across the batch dimension in the\n",
        "layer Dimension and we're going to end up with a 2 x 1 x 1 tensor\n",
        "\"\"\"\n",
        "mean = inputs.mean(dim=dims, keepdim=True)\n",
        "mean.size(), mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lEkVVi3M_8_",
        "outputId": "adc4e9a3-d0b9-4d98-be44-24c81a7dbd33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0.0817]],\n",
              "\n",
              "        [[0.1886]]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "we do the same kind of computation like we did before for computing \n",
        "the standard deviation \n",
        "\n",
        "now notice that we're adding some small Epsilon value to this\n",
        "variance and this is done to ensure because you know standard deviation is\n",
        "going to be a denominator over here it doesn't become zero\n",
        "\"\"\"\n",
        "\n",
        "# variance\n",
        "var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
        "epsilon = 1e-5\n",
        "std = (var + epsilon).sqrt()\n",
        "std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRokYqlDN6yJ",
        "outputId": "465fad1e-2a85-46eb-d97a-90d7980b4404"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.0000, -1.2238,  1.2238]],\n",
              "\n",
              "        [[ 1.4140, -0.7070, -0.7070]]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "so when we actually do the inputs minus the mean divided by standard deviation \n",
        "we will get the same exact Matrix that we kind of worked out \n",
        "by hand which is great\n",
        "\"\"\"\n",
        "y = (inputs - mean) / std\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cc8NMZVN_sQ",
        "outputId": "ffa36523-c9d9-42e7-be4a-7e04521c681b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.0000, -1.2238,  1.2238]],\n",
              "\n",
              "        [[ 1.4140, -0.7070, -0.7070]]], grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "now we're gonna multiply gamma that is a matrix of ones to all the values of Y\n",
        "and add zeros you're kind of still going to get the same exact Matrix\n",
        "\n",
        "but this time you'll notice this additional parameter (grad_fn=) \n",
        "over here  which means that it has learnable parameters in this case\n",
        "gamma and beta which are going to be updating during the actual back\n",
        "propagation phase\n",
        "\"\"\"\n",
        "out = gamma * y + beta\n",
        "out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO4x-axkv9j8"
      },
      "source": [
        "## Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MYJ2AE7Sv-Wc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class LayerNormalization():\n",
        "    def __init__(self, parameters_shape, eps=1e-5):\n",
        "        self.parameters_shape=parameters_shape\n",
        "        self.eps=eps\n",
        "        self.gamma = torch.nn.Parameter(torch.ones(parameters_shape))\n",
        "        self.beta =  torch.nn.Parameter(torch.zeros(parameters_shape))\n",
        "\n",
        "    def forward(self, input):\n",
        "        dims = [-(i + 1) for i in range(len(self.parameters_shape))]\n",
        "        mean = inputs.mean(dim=dims, keepdim=True)\n",
        "        print(f\"Mean \\n ({mean.size()}): \\n {mean}\")\n",
        "        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
        "        std = (var + self.eps).sqrt()\n",
        "        print(f\"Standard Deviation \\n ({std.size()}): \\n {std}\")\n",
        "        y = (inputs - mean) / std\n",
        "        print(f\"y \\n ({y.size()}) = \\n {y}\")\n",
        "        out = self.gamma * y  + self.beta\n",
        "        print(f\"out \\n ({out.size()}) = \\n {out}\")\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrnZx0HYyoRz",
        "outputId": "bef1604a-f390-475a-d7c3-363a8da8704f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input \n",
            " (torch.Size([5, 3, 8])) = \n",
            " tensor([[[-0.9336,  1.4350,  1.4550, -1.1124, -0.0604,  1.7027,  0.4845,\n",
            "          -0.6321],\n",
            "         [-2.0648,  0.9175,  0.9180,  0.7445,  0.7821, -0.8418, -0.0627,\n",
            "          -0.2638],\n",
            "         [-1.5282, -0.0943,  1.2761,  0.6899,  0.0288,  1.3201, -0.1306,\n",
            "          -1.8454]],\n",
            "\n",
            "        [[-1.3317,  2.0521,  0.7397,  0.2874, -1.7054, -0.2183,  0.1137,\n",
            "          -0.5181],\n",
            "         [ 0.7227, -0.0262, -1.6567, -2.0064, -0.0487, -1.1105,  0.2263,\n",
            "          -0.2071],\n",
            "         [ 0.4981, -1.0664,  0.1809,  0.0433,  0.0584, -0.9919, -1.3965,\n",
            "           0.3221]],\n",
            "\n",
            "        [[-0.8001,  1.4854,  0.1499,  0.1294,  1.0086,  0.2764,  0.3969,\n",
            "           0.0314],\n",
            "         [ 2.0431,  0.5838, -0.0537, -0.7300, -0.6818, -0.1660, -0.7880,\n",
            "          -0.3153],\n",
            "         [ 0.6759,  0.5725, -0.8026,  1.2495,  0.5475,  0.7430, -0.1975,\n",
            "           0.0752]],\n",
            "\n",
            "        [[-0.7739,  0.5131,  1.1141,  0.8539,  2.9295,  1.5332, -1.1278,\n",
            "          -1.5058],\n",
            "         [ 1.0423,  0.1607, -1.6228, -0.6596,  1.5170, -1.3469, -0.3336,\n",
            "          -1.4749],\n",
            "         [ 1.4396, -0.4850, -1.4031, -1.4317,  0.4072,  0.8904, -0.0763,\n",
            "          -0.4787]],\n",
            "\n",
            "        [[ 0.8128, -0.2292, -0.3520,  0.2190, -0.9904,  0.5322,  1.3287,\n",
            "           0.3250],\n",
            "         [-0.2155,  1.1517,  0.1151, -0.1665, -0.8004, -0.7975, -0.3228,\n",
            "          -1.0278],\n",
            "         [ 1.0736, -0.5814,  0.4769, -0.9455,  0.0643,  1.1479, -1.0450,\n",
            "          -0.6948]]])\n"
          ]
        }
      ],
      "source": [
        "batch_size = 3\n",
        "sentence_length = 5\n",
        "embedding_dim = 8 \n",
        "inputs = torch.randn(sentence_length, batch_size, embedding_dim)\n",
        "\n",
        "print(f\"input \\n ({inputs.size()}) = \\n {inputs}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3U3akvkFys68"
      },
      "outputs": [],
      "source": [
        "layer_norm = LayerNormalization(inputs.size()[-1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ9lt7LUy-g9",
        "outputId": "095997e4-1643-4e8c-e267-ea3b42ca61bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean \n",
            " (torch.Size([5, 3, 1])): \n",
            " tensor([[[ 0.2923],\n",
            "         [ 0.0161],\n",
            "         [-0.0355]],\n",
            "\n",
            "        [[-0.0726],\n",
            "         [-0.5133],\n",
            "         [-0.2940]],\n",
            "\n",
            "        [[ 0.3347],\n",
            "         [-0.0135],\n",
            "         [ 0.3579]],\n",
            "\n",
            "        [[ 0.4420],\n",
            "         [-0.3397],\n",
            "         [-0.1422]],\n",
            "\n",
            "        [[ 0.2058],\n",
            "         [-0.2580],\n",
            "         [-0.0630]]])\n",
            "Standard Deviation \n",
            " (torch.Size([5, 3, 1])): \n",
            " tensor([[[1.0688],\n",
            "         [0.9934],\n",
            "         [1.0957]],\n",
            "\n",
            "        [[1.1073],\n",
            "         [0.9024],\n",
            "         [0.6865]],\n",
            "\n",
            "        [[0.6366],\n",
            "         [0.8848],\n",
            "         [0.5981]],\n",
            "\n",
            "        [[1.4027],\n",
            "         [1.0988],\n",
            "         [0.9590]],\n",
            "\n",
            "        [[0.6784],\n",
            "         [0.6441],\n",
            "         [0.8274]]])\n",
            "y \n",
            " (torch.Size([5, 3, 8])) = \n",
            " tensor([[[-1.1470,  1.0691,  1.0878, -1.3143, -0.3301,  1.3196,  0.1798,\n",
            "          -0.8649],\n",
            "         [-2.0948,  0.9074,  0.9079,  0.7332,  0.7711, -0.8637, -0.0794,\n",
            "          -0.2818],\n",
            "         [-1.3623, -0.0537,  1.1970,  0.6620,  0.0586,  1.2371, -0.0868,\n",
            "          -1.6518]],\n",
            "\n",
            "        [[-1.1371,  1.9188,  0.7335,  0.3251, -1.4745, -0.1316,  0.1682,\n",
            "          -0.4024],\n",
            "         [ 1.3697,  0.5398, -1.2670, -1.6545,  0.5148, -0.6617,  0.8196,\n",
            "           0.3393],\n",
            "         [ 1.1540, -1.1252,  0.6918,  0.4914,  0.5133, -1.0167, -1.6061,\n",
            "           0.8975]],\n",
            "\n",
            "        [[-1.7827,  1.8076, -0.2903, -0.3226,  1.0587, -0.0917,  0.0976,\n",
            "          -0.4766],\n",
            "         [ 2.3245,  0.6751, -0.0454, -0.8098, -0.7554, -0.1724, -0.8754,\n",
            "          -0.3411],\n",
            "         [ 0.5316,  0.3588, -1.9404,  1.4907,  0.3169,  0.6438, -0.9287,\n",
            "          -0.4727]],\n",
            "\n",
            "        [[-0.8668,  0.0506,  0.4791,  0.2937,  1.7733,  0.7779, -1.1191,\n",
            "          -1.3886],\n",
            "         [ 1.2577,  0.4554, -1.1676, -0.2911,  1.6897, -0.9166,  0.0055,\n",
            "          -1.0331],\n",
            "         [ 1.6494, -0.3574, -1.3147, -1.3446,  0.5728,  1.0767,  0.0688,\n",
            "          -0.3509]],\n",
            "\n",
            "        [[ 0.8948, -0.6412, -0.8223,  0.0196, -1.7632,  0.4812,  1.6554,\n",
            "           0.1758],\n",
            "         [ 0.0658,  2.1886,  0.5793,  0.1421, -0.8422, -0.8377, -0.1007,\n",
            "          -1.1952],\n",
            "         [ 1.3736, -0.6265,  0.6525, -1.0666,  0.1538,  1.4635, -1.1868,\n",
            "          -0.7636]]])\n",
            "out \n",
            " (torch.Size([5, 3, 8])) = \n",
            " tensor([[[-1.1470,  1.0691,  1.0878, -1.3143, -0.3301,  1.3196,  0.1798,\n",
            "          -0.8649],\n",
            "         [-2.0948,  0.9074,  0.9079,  0.7332,  0.7711, -0.8637, -0.0794,\n",
            "          -0.2818],\n",
            "         [-1.3623, -0.0537,  1.1970,  0.6620,  0.0586,  1.2371, -0.0868,\n",
            "          -1.6518]],\n",
            "\n",
            "        [[-1.1371,  1.9188,  0.7335,  0.3251, -1.4745, -0.1316,  0.1682,\n",
            "          -0.4024],\n",
            "         [ 1.3697,  0.5398, -1.2670, -1.6545,  0.5148, -0.6617,  0.8196,\n",
            "           0.3393],\n",
            "         [ 1.1540, -1.1252,  0.6918,  0.4914,  0.5133, -1.0167, -1.6061,\n",
            "           0.8975]],\n",
            "\n",
            "        [[-1.7827,  1.8076, -0.2903, -0.3226,  1.0587, -0.0917,  0.0976,\n",
            "          -0.4766],\n",
            "         [ 2.3245,  0.6751, -0.0454, -0.8098, -0.7554, -0.1724, -0.8754,\n",
            "          -0.3411],\n",
            "         [ 0.5316,  0.3588, -1.9404,  1.4907,  0.3169,  0.6438, -0.9287,\n",
            "          -0.4727]],\n",
            "\n",
            "        [[-0.8668,  0.0506,  0.4791,  0.2937,  1.7733,  0.7779, -1.1191,\n",
            "          -1.3886],\n",
            "         [ 1.2577,  0.4554, -1.1676, -0.2911,  1.6897, -0.9166,  0.0055,\n",
            "          -1.0331],\n",
            "         [ 1.6494, -0.3574, -1.3147, -1.3446,  0.5728,  1.0767,  0.0688,\n",
            "          -0.3509]],\n",
            "\n",
            "        [[ 0.8948, -0.6412, -0.8223,  0.0196, -1.7632,  0.4812,  1.6554,\n",
            "           0.1758],\n",
            "         [ 0.0658,  2.1886,  0.5793,  0.1421, -0.8422, -0.8377, -0.1007,\n",
            "          -1.1952],\n",
            "         [ 1.3736, -0.6265,  0.6525, -1.0666,  0.1538,  1.4635, -1.1868,\n",
            "          -0.7636]]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "out = layer_norm.forward(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSUGdHwL6yD2",
        "outputId": "d892e7fe-c92c-4fa3-a2fa-856fde3ab116"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(2.9802e-08, grad_fn=<MeanBackward0>),\n",
              " tensor(1.0215, grad_fn=<StdBackward0>))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out[0].mean(), out[0].std()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "01fd550304b9e7cfb3e25c8e3ca63c0030fb0173de6652dd3d36373edc7c122f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
